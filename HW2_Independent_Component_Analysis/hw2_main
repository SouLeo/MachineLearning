from numpy import short
from numpy.core._multiarray_umath import ndarray
from scipy.io.wavfile import write
from sklearn.preprocessing import normalize

import scipy.io as sio
import numpy as np

from generate_mixing_matrix import generate_mixing_matrix
from cdf_guesstimate import cdf_eval

sound_mat = sio.loadmat('original_sound_data/sounds.mat')

unmixed_sounds = sound_mat['sounds']

# Generate original sound wav files
# sio.wavfile.write('original_sound_0', 44100, unmixed_sounds[0, :])
# sio.wavfile.write('original_sound_1', 44100, unmixed_sounds[1, :])
# sio.wavfile.write('original_sound_2', 44100, unmixed_sounds[2, :])
# sio.wavfile.write('original_sound_3', 44100, unmixed_sounds[3, :])
# sio.wavfile.write('original_sound_4', 44100, unmixed_sounds[4, :])

signals_to_mix = np.vstack((unmixed_sounds[3, :], unmixed_sounds[4, :]))

num_of_source_signals = signals_to_mix.shape[0]
num_of_mixed_signals = 2
learning_rate = 0.1  # adjust for gradient descent

mixing_matrix = generate_mixing_matrix(num_of_mixed_signals, num_of_source_signals)
mixed_signals = np.matmul(mixing_matrix, signals_to_mix)
# print(mixed_signals.shape)
mixed_signals_scaled = mixed_signals
# print(mixed_signals_scaled)
# mixed_signals_scaled = np.int16(mixed_signals.transpose()/np.max(np.abs(mixed_signals.transpose())) * 32767).transpose()
mixed_signals_scaled = np.vstack((mixed_signals_scaled[0, :], mixed_signals_scaled[0, :]))
# mixed_signals_scaled = normalize(mixed_signals_scaled)
# print(mixed_signals_scaled)

# print(np.ndarray.min(mixed_signals_scaled))
# print(np.ndarray.max(mixed_signals_scaled))
# print(mixed_signals_scaled.shape)
# Generates mixed sound wav file
# sio.wavfile.write('mixed_sound_data/mixed_sound_0_1', 44100, mixed_signals_scaled)

# Create W Matrix (n by m) to recover the original n source signals
W = 2*np.random.rand(num_of_source_signals, num_of_mixed_signals)
# TODO: Create Gradient Descent Loop Here
# converged = False
# while not converged:
for i in range(500):
    # Step 3
    curr_source_estimate = np.matmul(W, mixed_signals_scaled)
    # Step 4
    Z = cdf_eval(curr_source_estimate)
    # Step 5
    del_W = 1-2*Z
    del_W = 1/44000*np.matmul(del_W, curr_source_estimate.transpose())
    del_W = np.identity(2) + del_W
    del_W = del_W * learning_rate
    del_W = np.matmul(del_W, W)
    # del_W = learning_rate*np.matmul((np.identity(2) + np.matmul((1-2*Z), curr_source_estimate.transpose())), W)
    # Step 6
    W = W + del_W
    dist = np.linalg.norm(curr_source_estimate-signals_to_mix)
    # if dist < 20:
    #     print("True")
    #     converged = True
t1 = np.int16(curr_source_estimate[0, :] / np.max(np.abs(curr_source_estimate[0, :])) * 32767)
sio.wavfile.write('unmixed_sound_data/unmixed_sound_0', 44100, t1)

t2 = np.int16(curr_source_estimate[1, :] / np.max(np.abs(curr_source_estimate[1, :])) * 32767)
sio.wavfile.write('unmixed_sound_data/unmixed_sound_1', 44100, t2)
print('done')
